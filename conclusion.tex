% Prelim, Chapter 5
% by Rachel Slaybaugh

\chapter{Summary}
\label{sec:Chp5}
To enhance and improve the design of nuclear systems, high-fidelity neutron fluxes are required. For today's problems, high-fidelity  means thousands $\times$ thousands $\times$ thousands of mesh points, up to $\sim$150 energy groups, accurate scattering expansions, and the use of many directions. Leadership-class machines provide platforms on which problems of this size can be solved in a reasonable amount of time. Computing such fluxes accurately and efficiently requires numerical methods with good convergence properties and algorithms that can scale to hundreds of thousands of cores. 

Many 3-D deterministic transport codes can scale in space and angle to tens of thousands of cores. They typically rely on methods such as Gauss Seidel for fixed source problems and power iteration for eigenvalue problems. Within group solvers range from source iteration to Krylov methods. In many cases these methods are accelerated with strategies like CMR, TTG, DSA, and others discussed earlier in this document. Nevertheless, these problems can be slow to converge for challenging problems like those with highly scattering materials or high dominance ratios. 

Three methods have been added to Denovo that are designed to improve convergence and enable the full use of cutting-edge computers. The driving idea behind all of this research was to use Rayleigh quotient iteration for solving the $k$-eigenvalue problem in 3-D neutron transport. This objective was not tractable with the tools originally available in Denovo. The multigroup Krylov solver and multigrid in energy preconditioner were developed to facilitate RQI, though both of these tools are also useful on their own. This chapter reviews each method, highlights associated results, and closes with some discussion about their potential impact. 

\section{Multigroup Krylov Solver}
Before this work began, Denovo had been shown to scale well in space and angle up to about 20,000 cores. It also used Gauss Seidel as its multigroup solver. The first method added was a multigroup Krylov solver that was designed to improve convergence when compared to Gauss Seidel and to dramatically increase the number cores Denovo can use. 

Instead of sequentially solving each group with some inner iteration method and then using GS for outer iterations, the MG Krylov solver converges all upscattering groups at once such that the inner-outer iteration structure is removed. Using a Krylov method over the upscattering block instead of GS resulted in much faster convergence, both in terms of time and iteration count. The author did not find any other code that applied Krylov solvers over a block of groups without also needing inner iterations. 

In addition, the block Krylov solver allows energy groups to be solved simultaneously because the multigroup-sized matrix vector multiply can be divided up in energy and parallelized. The upscattering block is broken into energy sets and each set is handled by a different group of cores. The spatial decomposition does not change, and each set gets the entire spatial mesh so space-angle scaling remains intact. The author is unaware of any other \Sn transport code that is parallelized in the energy dimension. Energy sets extend the number of cores that can be used efficiently by Denovo from tens of thousands to hundreds of thousands. 

Two test problems were used to investigate the new method's functionality, how it compares to GS, and how it scales in energy. The small fixed source, iron graphite cube showed that the Krylov solver was much faster than unaccelerated GS. The use of graphite made this problem particularly challenging for GS. A full PWR was also studied with power iteration as the eigenvalue solver. The 2-group versions of this problem showed the MG Krylov solver to be much faster than accelerated GS. Both tests confirmed that the new multigroup Krylov solver has the potential to substantially outperform Gauss Seidel in challenging cases and problems of interest.  

The effect of using energy sets was also investigated with both test problems. The iron graphite cube verified that the new MG solver works successfully with multisets. The large PWR problem that had over 1.7 trillion degrees of freedom was used to investigate strong scaling. Three cases that used different combinations of $\sim$100,000 or $\sim$200,000 cores, and 11 or 22 energy sets were computed on Jaguar. This is exactly the type and scale of calculation the MG Krylov solver was made to handle.

The strong scaling study gave mixed results. Initially, doubling the energy sets with approximately the same spatial decomposition yielded 80\% efficient scaling. Doubling the spatial blocks with the energy sets held constant gave 86\% efficient scaling. Both of those numbers are great. However, some communication was optimized in Denovo and the energy scaling cases were repeated. This reduced the efficiency to only 62\%. Some improvement in the multiset communication has been implemented since these results were found, but the tests have not been repeated to see the effect on energy scaling. 

The PWR problem was also used for a weak scaling study. The ratio of calculated time to ideal time was 1.019 when the problem was expanded from 17,424 cores to 112,200 cores. The weak scaling performance was very good. 

The ideas behind the multigroup Krylov solver have not been previously pursued because of computer architecture limitations in the past. It is only now that there are machines with memories large enough to accommodate such large Krylov subspaces and that have enough cores to warrant the capability to use hundreds of thousands of cores. Denovo was used successfully on a machine of this size for a real problem because of the new energy decomposition. The test problems demonstrated that the new method decisively accomplishes the goal of accelerating transport calculations by using new computers fully.

\section{Rayleigh Quotient Iteration}
Finding the criticality state of a multiplying nuclear system is one of the most important kinds of analysis done for nuclear systems. The standard eigenvalue solution methods can be slow in many instances. To design new reactors, a better eigenvalue solver is needed. Rayleigh quotient iteration in an eigenvalue method that finds the dominant eigenvalue in an optimal way, and theory indicates that RQI should converge in fewer iterations than traditional eigenvalue solvers.

The addition of RQI, though, would not be possible without the MG Krylov solver. Within Denovo, the Rayleigh quotient in RQI multiplies the fission matrix which is then subtracted from the scattering matrix. This makes it look like every energy group has upscattering and the scattering matrix becomes energy-block dense. Handling energy-block dense systems when there are more than a few energy groups was not tractable before the new multigroup method was added. It is only the MG Krylov solver that makes RQI a reasonable idea when there are many energy groups.

In return, RQI takes fuller advantage of the energy parallelization made available by the block Krylov solver than power iteration or fixed source solves can. Every group can be solved simultaneously since every group looks like it has upscattering. In the upper limit, there can be as many energy sets as groups in a problem. It only makes sense to do that with RQI. 

There are, however, some drawbacks to using RQI with a Krylov method. The system becomes ill-conditioned when the Rayleigh quotient is close to the eigenvalue being sought. The closer RQI comes to solving the problem, the worse the conditioning becomes. Krylov methods can converge very slowly and may not be backwards stable for ill-conditioned problems. If the multigroup iterations do not converge the eigenvector inside the RQI calculations, and then RQI itself will not converge as it will not be able to find an accurate RQ.

Three sizes of problems, small, medium, and large, were used to test whether RQI converges in fewer iterations than power iteration and whether the shift prevents the Krylov solver from converging. Two small problems, one with reflecting and one with vacuum boundaries, demonstrated that RQI could correctly find the eigenvalue and eigenvector in fewer iterations than power iteration. 

The intermediately sized problem with reflecting boundary conditions did not work as well. The Krylov solver was not able to converge the flux moments in a reasonable number of iterations. Then the eigenvalue part of the calculation did not converge because there was not an accurate eigenvector from which to make the eigenvalue guess. This problem seemed to have an eigenvector guess that was close to correct, though, because the RQI-computed eigenvalue only differed from the reference $k$ by 0.0033. 

With two benchmark reactor problems, RQI did not work at all. The multigroup iterations did not converge and the eigenvalue was not close to the reference. While the answers were not necessarily what was desired, these tests answer the questions asked. One answer is that RQI can work and can converge more quickly than power iteration, thus it has promise for accelerating eigenvalue calculations. 

Another is that for real problems the matrix system becomes too ill-conditioned to work with a Krylov solver. That means that preconditioning is needed for RQI to be useful when solving real problems. An examination of the eigenvector residual in an unconverged multigroup iteration suggests that a multigrid method might work very well as a preconditioner. 

If preconditioning can get the Krylov multigroup solves to converge, then RQI will likely be a successful method. It will solve at least some challenging problems in fewer eigenvalue and total Krylov iterations than the other methods available in Denovo. 

Despite the clear theoretical edge RQI has over other methods, it has never been used for 3-D neutron transport before. This is largely because of the application of the shift. Traditional multigroup solvers like Gauss Seidel cannot treat energy-block dense scattering systems efficiently. The MG Krylov solver lets RQI to be used in this context, and enables the parallelization of eigenvalue calculations to hundreds of thousands of cores. 

\section{Multigrid in Energy}

%Another potential way to reduce the time to solution for a given calculation is by reducing the number of iterations needed for convergence through preconditioning. If the savings from a lower iteration count is more than cost of the extra work done in making and applying the preconditioner, the result is a faster code. 

%Two classes of preconditioners are proposed. The first is a multilevel energy preconditioner. Iterative methods reduce oscillatory error effectively, but not smooth error. If the transport equation is restricted to coarser energy grids, the error modes that appeared smooth on the fine grid become oscillatory. An iterative scheme can be applied on the coarse grids to reduce the error components that appear oscillatory on these grids. Finally, the problem can be prolongated back to the fine energy grid where the troublesome error modes have now been removed. 

%A multilevel method has never been applied to the energy portion of phase space for the neutron transport problem before. The smoother that will be used for the multilevel energy preconditioner will be either Jacobi or successive over relaxation. The new preconditioner will also take advantage of the energy set decomposition such that it can be parallelized. It will be tested on problems with many energy groups to provide a wide range of grid and set combinations. 

%The intention is that $\ve{M}^{-1}$ will be sufficiently close to $\ve{A}^{-1}$ to provide acceleration. It will be fairly inexpensive to form $\ve{M}^{-1}$. This preconditioner will also be parallelized. The shifted scattering preconditioner will be tested on criticality problems that are traditionally difficult for \Sn methods to solve. Because the shifted scattering matrix is new, the preconditioner is also  new.

%Both preconditioners will be used on a toy problem for verification. They will also be applied to a large scale real PWR problem to investigate their influence on problems of interest. One of the goals of this research is to categorize which types of problems benefit from which preconditioners. An important and related area of research will be the tradeoff between the cost of construction and application of the preconditioners, and the change in solution time as a function of parallelization. 


This means the preconditioner may be useful for many problems types. The preconditioner seemed to always work well for fixed source problems and with power iteration. For tough problems of either type the preconditioner could prove to be very beneficial once it has been optimized.  

Problems that RQI could not solve without preconditioning converged with it. Preconditioned RQI was a little more brittle than fixed source or PI. The preconditioning did not always work well for problems that RQI could already solve. It did seem to work for all of the ones that it could not. In addition, reflecting boundaries seem to be much more troublesome for RQI than vacuum. 

For the kinds of problems we actually care about, it seems like RQI works better than PI. For the easy problems, PI was better. We didn't have a lot of great test problems to really figure this out though. The multigrid method worked very well with multisets and scaled very well. 

RQI is a somewhat brittle method. It does not always work because of this ill-conditioning issue. When it does work, it works very well. As a general rule, the output of RQI should not be trusted if the Krylov iterations do not converge on every iteration, even if $k$ does converge. In the cases where this happened the $k$ was usually correct, but it was not always correct. To be certain, only consider $k$ valid when all of the multigroup iterations converge. To help ensure the eigenvector is converged, a moderate amount of preconditioning (e.g.\ $w1r3v3$) should be used. 

\section{Closing Remarks}
Denovo can now be decomposed in energy for fixed source calculations. Test problems showed the new method exhibited good strong and weak scaling in energy. This capability will soon be available for eigenvalue problems. Parallelizing over this part of phase space allows Denovo to overcome the limitations inherent in KBA. Thus, Denovo will be able to scale to $O(100,000)$ cores for all challenging problems. 

The new solution methods for fixed source and eigenvalue problems not only enable parallelization in energy, but will also reduce time to solution for the same number of processors. Using a Krylov solver instead of Gauss Seidel for fixed source problems improved convergence for the problems tested. The addition of the shifted RQI method will similarly accelerate criticality problems with high dominance ratios. This improvement will be most beneficial for the problems that are currently the most difficult to converge.

Finally, adding new preconditioners should reduce the number of iterations needed for a given calculation. While the benefit of the proposed preconditioners is the least certain, it is likely they will be useful for at least some problems. 

Overall, the research proposed in this document will accelerate Denovo in multiple ways. This acceleration is crucial for enabling the solution of today's ``grand challenge'' problems. It is hoped that improved methods will lead to improved reactor designs and systems, and that the frontier of computational challenges will be moved forward.  


