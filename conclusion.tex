% Thesis, Chapter 5
% by Rachel Slaybaugh

\chapter{Summary}
\label{sec:Chp5}
To enhance and improve the design of nuclear systems, high-fidelity neutron fluxes are required. For today's problems, high-fidelity means thousands $\times$ thousands $\times$ thousands of mesh points, up to $\sim$150 energy groups, accurate scattering expansions, and the use of many directions. Leadership-class machines provide platforms on which problems of this size can be solved in a reasonable amount of time. Computing such fluxes accurately and efficiently requires numerical methods with good convergence properties and algorithms that can scale to hundreds of thousands of cores. 

Many 3-D deterministic transport codes can scale in space and angle to tens of thousands of cores. They typically rely on methods such as Gauss Seidel for fixed source problems and power iteration for eigenvalue problems. Within group solvers range from source iteration to Krylov methods. In many cases these methods are accelerated with strategies like CMR, TTG, DSA, and others discussed earlier in this document. Nevertheless, these problems can be slow to converge for challenging problems like those with highly scattering materials or high dominance ratios. 

Three methods have been added to Denovo that are designed to improve convergence and enable the full use of cutting-edge computers. The idea driving all of this research is to use Rayleigh quotient iteration for solving the $k$-eigenvalue problem in 3-D neutron transport. This objective was not tractable with the tools originally available in Denovo. The multigroup Krylov solver and multigrid in energy preconditioner were developed to facilitate RQI, though both of these tools are also useful on their own. This chapter reviews each method, highlights associated results, suggests future work that will increase understanding and improve performance of the methods, and closes with some discussion about their potential impact. 

\section{Multigroup Krylov Solver}
Before this work began, Denovo had been shown to scale well in space and angle up to about 20,000 cores. It also used Gauss Seidel as its multigroup solver. The first method added was a multigroup Krylov solver that was designed to improve convergence when compared to Gauss Seidel and to dramatically increase the number cores Denovo can use. 

Instead of sequentially solving each group with some inner iteration method and then using GS for outer iterations, the MG Krylov solver treats all upscattering groups at once such that the inner-outer iteration structure is removed. Using a Krylov method over the upscattering block instead of GS resulted in much faster convergence, both in terms of time and iteration count. No other transport codes were found that apply Krylov solvers over a block of groups without also needing inner iterations. 

In addition, the block Krylov solver allows energy groups to be solved simultaneously because the multigroup-sized matrix vector multiply can be divided up in energy and parallelized. The upscattering block is broken into energy sets and each set is handled by a different group of cores. The spatial decomposition does not change, and each set gets the entire spatial mesh such that space-angle scaling remains intact.  Other \Sn transport codes that are parallelized in the energy dimension could not be found. Energy sets extend the number of cores that can be used efficiently by Denovo from tens of thousands to hundreds of thousands. 

Three test problems were used to investigate how the new method compares to GS, and how it scales in energy. The iron graphite cube and PWR900 tests showed MG Krylov to be much faster than GS, even when GS is accelerated. Once the multiset communication was optimized, the strong scaling performance of block Krylov was shown to be nearly perfect to 50,000 cores and reasonable to 200,000 cores. Weak scaling in energy was very good. The addition of energy sets enabled Denovo to use 100,000 and 200,000 cores with reasonable efficiency, that would not have been possible for the same problems with KBA alone. 

%Two test problems were used to investigate the new method's functionality, how it compares to GS, and how it scales in energy. The small fixed source, iron graphite cube showed that the Krylov solver was much faster than unaccelerated GS. The use of graphite made this problem particularly challenging for GS. A full PWR was also studied with power iteration as the eigenvalue solver. The 2-group versions of this problem showed the MG Krylov solver to be much faster than accelerated GS. Both tests confirmed that the new multigroup Krylov solver has the potential to substantially outperform Gauss Seidel in challenging cases and problems of interest.  

%The effect of using energy sets was also investigated with both test problems. The iron graphite cube verified that the new MG solver works successfully with multisets. The large PWR problem that had over 1.7 trillion degrees of freedom was used to investigate strong scaling. Three cases that used different combinations of $\sim$100,000 or $\sim$200,000 cores, and 11 or 22 energy sets were computed on Jaguar. This is exactly the type and scale of calculation the MG Krylov solver was made to handle.

%The strong scaling study gave mixed results. Initially, doubling the energy sets with approximately the same spatial decomposition yielded 80\% efficient scaling. Doubling the spatial blocks with the energy sets held constant gave 86\% efficient scaling. Both of those numbers are great. However, some communication was optimized in Denovo and the energy scaling cases were repeated. This reduced the efficiency to only 62\%. Some improvement in the multiset communication has been implemented since these results were found, but the tests have not been repeated to see the effect on energy scaling. 

%The PWR problem was also used for a weak scaling study. The ratio of calculated time to ideal time was 1.019 when the problem was expanded from 17,424 cores to 112,200 cores. The weak scaling performance was very good. 

The ideas behind the multigroup Krylov solver have not been previously pursued because of computer architecture limitations in the past. It is only now that there are machines with memories large enough to accommodate such large Krylov subspaces and that have enough cores to warrant the capability to use hundreds of thousands of cores. Denovo was used successfully on a machine of this size for a real problem because of the new energy decomposition. The test problems demonstrated that the new method decisively accomplishes the goal of accelerating transport calculations by using new computers fully.

\section{Rayleigh Quotient Iteration}
Finding the criticality state of a multiplying nuclear system is one of the most important kinds of analysis done for nuclear systems. The standard eigenvalue solution methods can be slow in many instances. To design new reactors, a better eigenvalue solver is needed. Rayleigh quotient iteration in an eigenvalue method that finds the dominant eigenvalue in an optimal way, and theory indicates that RQI should converge in fewer iterations than traditional eigenvalue solvers.

The addition of RQI, though, would not be possible without the MG Krylov solver. Within Denovo, the Rayleigh quotient in RQI multiplies the fission matrix which is then subtracted from the scattering matrix. This makes it look like every energy group has upscattering so the scattering matrix becomes energy-block dense. Handling energy-block dense systems when there are more than a few energy groups is not tractable with GS as the multigroup solver. It is only the MG Krylov solver that makes RQI a reasonable idea when there are many energy groups.

In return, RQI takes fuller advantage of the energy parallelization made available by the block Krylov solver than power iteration or fixed source solves can. Every group can be solved simultaneously since every group looks like it has upscattering. In the upper limit, there can be as many energy sets as groups in a problem. This degree of energy parallelization only makes sense with RQI. 

There is, however, a drawback that comes from using RQI with a Krylov method. When the Rayleigh quotient is close to the eigenvalue being sought the system becomes ill-conditioned. The closer RQI comes to solving the problem, the worse the conditioning becomes. Krylov methods can converge very slowly and may not be backwards stable for ill-conditioned problems. If the multigroup iterations do not converge the eigenvector inside the RQI calculations, then RQI itself will not converge as it will not be able to find an accurate RQ.

Three sizes of problems, small, medium, and large, were used to test whether RQI requires fewer iterations than power iteration and whether the shift prevents the Krylov solver from converging. The small problems showed RQI could correctly find the eigenvalue and eigenvector in fewer iterations than power iteration. RQI began to falter with the medium problem, finding an eigenvalue only close to the reference and failing to converge the eigenvalue or vector. With the large problems RQI did not work at all.

%Two small problems, one with reflecting and one with vacuum boundaries, demonstrated that RQI could correctly find the eigenvalue and eigenvector in fewer iterations than power iteration. 

%The intermediately sized problem with reflecting boundary conditions did not work as well. The Krylov solver was not able to converge the flux moments in a reasonable number of iterations. Then the eigenvalue part of the calculation did not converge because there was not an accurate eigenvector from which to make the eigenvalue guess. This problem seemed to have an eigenvector guess that was close to correct, though, because the RQI-computed eigenvalue only differed from the reference $k$ by 0.0033. With two benchmark reactor problems, RQI did not work at all. The multigroup iterations did not converge and the eigenvalue was not close to the reference. 

While the results were not necessarily what was desired, the tests answer the questions asked. One answer is that RQI can work and can converge more quickly than power iteration, thus it has promise for accelerating eigenvalue calculations. Another is that for real problems the matrix system becomes too ill-conditioned to work with a Krylov solver. If preconditioning can get the Krylov multigroup solves to converge, then RQI will likely be a successful method. It will solve at least some challenging problems in fewer eigenvalue and total Krylov iterations than power iteration. 

Despite the clear theoretical edge RQI has over other methods, it has never been used for 3-D neutron transport before. This is largely because of the application of the shift. Traditional multigroup solvers like Gauss Seidel cannot treat energy-block dense scattering systems efficiently. The MG Krylov solver lets RQI be used in this context, and enables the parallelization of eigenvalue calculations to hundreds of thousands of cores. 

\section{Multigrid in Energy}
Another way to reduce calculation time is by reducing the number of iterations needed for convergence through preconditioning. %If the savings from a lower iteration count is more than the cost of the extra work done in making and applying the preconditioner, the result is a faster code. 
A multigrid in energy preconditioner was added to Denovo to reduce iteration count for all problem types, and to address the convergence issues arising from RQI. 

Iterative methods reduce oscillatory error effectively, but not smooth error. The smooth error can prevent iterative methods from converging. This behavior is characterized by rapid error reduction in the first several iterations followed by very little error reduction. This type of trend was observed when RQI failed. Multigrid methods selectively remove smooth error components and are therefore ideal for accelerating this type of problem. Thus, this preconditioner should work very well with RQI. 

%Restricting a problem from a fine energy grid to a coarser energy grid makes the error modes that appeared smooth on the fine grid become oscillatory. An iterative scheme can be applied on the coarse grid to reduce the error components that appear oscillatory there. The problem can then be prolonged back to the fine energy grid where the troublesome error modes have now been removed. 

The multigrid preconditioner is implemented in a way that easily and efficiently takes advantage of the new energy decomposition. The multigrid algorithm is applied within each energy set such that the energy groups are only restricted and prolonged between groups on that set. Sets do not have to communicate with one another in the preconditioner, and using more sets creates fewer total grid levels. An alternative strategy that was not investigated is to restrict groups across sets such that the total number of grid levels is set-count independent. 

Many tests were done to investigate the behavior of the new preconditioner. All of the tests showed that the preconditioner can be useful for many problems types: reflecting and vacuum boundaries, few and many groups, fixed source and eigenvalue. The preconditioner always worked well for fixed source problems. Multigrid in energy also dramatically reduced iteration count in all tests with power iteration. 

The preconditioning did not always work well for problems that RQI could already solve, though these were easy problems that did not need to be preconditioned. More importantly, though, problems that RQI could not solve without preconditioning did converge with it. As problems became more realistic, RQI benefited more from preconditioning. RQI used fewer iterations and was substantially faster than power iteration for the full-facility PWR.

There was one test RQI did not handle well. It highlighted that RQI is a somewhat brittle method that does not always work because of the ill-conditioning issue. When it does work, it works very well. As a general rule, the output of RQI should not be trusted if the Krylov iterations do not converge on every iteration, even if $k$ does converge. $k$ should only be considered valid when all of the multigroup iterations converge. To help ensure the eigenvector is converged for real problems, a moderate amount of preconditioning (e.g.\ $w1r3v3$) should be used. 

%The preconditioner always worked well for fixed source problems. The number of iterations were reduced for the vacuum and reflecting unit tests as well as for the iron and graphite cube problem. Multigrid in energy also always worked well with power iteration, dramatically reducing iteration count in all tests. 

%For tough fixed source and eigenvalue problems solved with PI, the preconditioner could prove to be very beneficial once it has been optimized. The timing comparisons were not favorable, but there are a several suggestions in the future work section that could remedy this.

%With RQI, the preconditioning did not always work well for problems that RQI could already solve, though these were easy problems that did not need to be preconditioned. In these simple cases preconditioned power iteration worked better than preconditioned RQI. All of the tests where this was the case had low dominance ratios. The spectral properties of these systems are good for PI and are not necessarily as good for RQI.

%Problems that RQI could not solve without preconditioning did converge with it. As problems became more realistic, RQI benefited more from preconditioning. For the 2-D benchmark problem, RQI worked well and was slightly inferior to preconditioned PI. In the 3-D benchmark study RQI performed better than PI for intermediate and large amounts of preconditioning. RQI was substantially better than PI in the full-facility PWR test case.

%The one trouble case was the intermediate infinite medium problem. RQI always had difficultly and preconditioning did not help much. It is unclear why this happened. It seemed that RQI did not perform as well for any problem that had six reflecting boundaries, though this was the only such case where RQI was unreliable. Power iteration, however, solved the problem without issue. 

%This test highlights that RQI is a somewhat brittle method. It does not always work because of the ill-conditioning issue. When it does work, it works very well. As a general rule, the output of RQI should not be trusted if the Krylov iterations do not converge on every iteration, even if $k$ does converge. In the cases where this happened the $k$ was usually correct, but it was not always correct. $k$ should only be considered valid when all of the multigroup iterations converge. To help ensure the eigenvector is converged for real problems, a moderate amount of preconditioning (e.g.\ $w1r3v3$) should be used. 

The multigrid method worked efficiently with multisets and scaled very well. %This is likely for two reasons. One is that the preconditioner did not add inter-set communication, so changing the number of sets does not increase the cost of the preconditioner from a communication standpoint. The second is that the reduction in number of grids makes the preconditioner less expensive with increasing set count. 
%
Not only were there no negative impacts from using more energy sets in the preconditioner, but scaling was actually improved by its use. The energy scaling performance with this implementation of the multigrid in energy method suggests that this parallelization strategy is better than the one that communicates across sets. 

A multigrid method has never been applied to the energy portion of phase space for the neutron transport problem before. This is not surprising because the motivation for the preconditioner is relatively new as well. Only in the last few years have energy parallelization and Rayleigh quotient iteration become feasible. Without those drivers there was no reason to do multigrid in energy.

\section{Suggested Future Work}
While many interesting things about these three methods have been found, there are still many questions to be answered. There are also a few remaining implementation details that will make these methods more flexible. Here are some ideas for further investigation that could guide how and when these methods should be used and could lead to their improvement. Some of these ideas require implementation, and some are simply tests.

Rayleigh quotient iteration can not be used with energy sets when there are reflecting boundaries. This capability should be added as it vastly expands the number of problems that can be used to study energy scaling with RQI. For example, the 2-D and 3-D c5g7 benchmark problems would then be available for these kinds of tests. 

Using a reduced number of solution directions inside the preconditioner is also not available when there are reflecting boundaries. This option seems like it may be very useful for reducing the time taken by the preconditioner. Ensuring all problems have this tool available will increase the benefit of preconditioning for problems using anything besides $S_{2}$.

Related to this, how much benefit is gained by using the smaller angle set in the preconditioner should be quantified. If it is found that the benefit is large and there is little or no impact on iteration reduction, then the default behavior could be changed to always use $S_{2}$, or $S_{N/2}$, etc.\ in the preconditioner with an input option to specify something else if desired. 

More full-facility PWR900 studies should be done to continue to see how the methods perform on a real problem. It would be useful to compare the preconditioned cases to unpreconditioned cases that used the same tolerances. It would also be very helpful to run the PI calculations to their conclusion. Finally, this problems uses $S_{12}$, making it a very good candidate for trying smaller angle sets in the preconditioner. 

Most of the problems where direct comparison between PI and RQI was possible did not have characteristics that represented the kinds of problems that scientists want to solve in practice. It would be informative to use more test problems with more difficult properties, such as high dominance ratios, to compare preconditioned RQI and PI. 

A more research-oriented line of investigation is to try different ways to test for convergence within RQI. Right now the current Rayleigh quotient is compared to the previous one. A different criterion might be better or lead to more accuracy. One idea is to use the eigenvector instead of the eigenvalue. There has also been some convergence analysis for RQI and research discussing interesting ways to set RQI convergence criteria that would inform this research. See for example Notay \cite{Notay2003} and Szyld \cite{Szyld2011}.
  
A crucial area of work is optimizing the preconditioner so that it is faster and more efficient. The multiset tests indicate that reducing the total number of energy grids to two or three regardless of the number of energy groups will not impact the iteration reduction gained from preconditioning. This change alone will greatly reduce the time the preconditioner takes for problems with more than a few energy groups. A few different grid depths should be investigated to assess what is best. Much speed can probably be gained by more efficient C++ coding as well. 

Once ideal V-cycle depth has been determined and any C++-related optimization has been added, many of the comparison studies should be repeated and considered for time. Energy scaling studies will also be needed to learn how the preconditioner scales with a different implementation of the number of grid levels. 
  
One final research-oriented idea is to consider using other relaxation methods besides weighted Richardson. It may be that something like Jacobi, or successive over relaxation, or another iterative method would work better. The behavior of the weight parameter inside the preconditioner was difficult to characterize in a generic way and occasionally caused poor behavior. Weight is the only parameter that is specifically related to Richardson. Another method would avoid that difficulty and could be more robust as a result. 

There are a variety of ideas here, some requiring more time and effort than others. Implementing a shallower default V-cycle will be easy to implement. Adding reduced angle sets and RQI + multisets for reflecting boundaries may be more work, but will be important to have. Using a different RQI convergence strategy or a different relaxation method are topics that likely require mathematical analysis and more in depth research. Finally, more testing should be done to improve understanding of the new methods and their impacts in different scenarios.  

\section{Closing Remarks}
The goal of this research was to accelerate transport calculations with methods that use new computers fully, facilitating the design of better nuclear systems. Three complimentary methods were implemented that accomplished this goal. 

At the outset of this work, Denovo could be decomposed in five of the six dimensions of phase space over which the steady-state transport equation is solved in a way that restricted it to about 20,000 cores for a problem with 500 million cells. The original suite of solvers included Gauss-Seidel as the multigroup solver and power iteration as the eigenvalue solver. These solvers have some significant limitations in many cases of interest. 

The new multigroup Krylov solver converges more quickly than GS and enables energy decomposition such that Denovo can scale to hundreds of thousands of cores. The new multigrid in energy preconditioner reduces iteration count for many problem types and takes advantage of the new energy decomposition such that it can scale very efficiently. These two tools are useful on their own, but together they allow the Rayleigh quotient iteration eigenvalue solver to work.

The real motivation of this work was to add RQI, which should converge in fewer iterations that power iteration for large and challenging problems. RQI creates shifted systems that would not be tractable without the MG Krylov solver. It also creates ill-conditioned matrices that cannot converge without the multigrid in energy preconditioner. Using these methods, RQI converged in fewer iterations and in less time than preconditioned PI for a full-facility PWR on 200,000 cores. 

The methods added in this research accelerated Denovo in multiple ways. This acceleration is crucial for enabling the solution of today's ``grand challenge'' problems. It is hoped that improved methods will lead to improved reactor designs and systems, and that the frontier of computational challenges will be moved forward.  


\separatorpage{}
