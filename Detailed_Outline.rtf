{\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf360
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww13600\viewh14080\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\ql\qnatural\pardirnatural

\f0\fs30 \cf0 1. Introduction\
- why we care about nuclear technology\
- what the neutron transport equation (TE) is, why it's important for development of nuclear technology, and why increased accuracy matters\
- goal of this work and how this document will tell you about accomplishing that goal \

\b    goal: "accelerate transport calculations with methods that use new computers fully, facilitating the design of better nuclear systems"
\b0\fs28 \
   Three complimentary methods have been implemented to accomplish this goal. In the following chapters background information, past work, mathematics and implementation, and results will be discussed for each method in turn. \
\
- preview of chapter: foundation for document\
   what has been, is being, and could be solved and why we care\
   details about the transport equation\
   how each method will help meet the goal\
\
 1.1 Motivation\
 - what do these problems look like?\
     physical problems of interest\
     when solved mathematically, the calculations can be large with fine discretizations\
 - old computers weren't big enough for fine discretizations\
 - to compensate, many approximations/simplifications were made\
 - those approximations meant we had to build conservatism into designs. We'd like to remove approximations to improve designs\
\
  1.1.1 Problems of Interest\
  - the problems we're solving today are really big and pushing the limits of our ability, here are some examples\
  - what we'd really like to solve, "grand challenge" problems, are even bigger\
\
  1.1.2 Enabling Technology\
  - larger computers (memory and computational power) allow us to reduce approximations and simplifications  \
  - this work made tools that use these computers efficiently so we can solve those big problems\
\
 1.2 The Transport Equation\
 - before delving into the methods, need to understand the TE: what this equation describes\
 - description of cross sections, fission, and criticality. \
 - transport equation and term definition; there is fixed source and eigenvalue\
 - characteristics of the equation. \
 - equation is discretized in space, energy, and angle; we're doing deterministic discrete ordinates method and neglecting spatial discretization concerns\
\
  1.2.1 Multigroup Approximation (energy)\
   - math and explanation\
  1.2.2 Scattering Discretization (angle)\
   - math and explanation\
  1.2.3 Discrete Ordinates Approximation (angle)\
   - math and explanation\
  1.2.4 Operator Form\
  - combine all the discretizations to express the problem in matrix form\
  - relate moments to angular flux (discrete to moment, phi = D psi)\
  - Ax = b form\
  - define sizes of matrices, notation for variable discretization\
  - here's what the matrices look like\
  1.2.5 Solution Procedure\
  - within group equations\
  - outer iteration over all groups\
  - one more iteration if there's a k\
\
 1.3 Meeting the Goal\
 - paragraph summarizing motivation and challenges, reminder of goal of work\
 - using denovo for work; \
 - denovo was parallelized in space and angle only when I started - shown not to be enough\
 - denovo uses xxx solver methods, (to be explained in detail later) that are not sufficient\
 - to improve denovo to accomplish goal:\
    1) parallelize in energy and reduce upscatter solve time: block Krylov\
        - converges faster than previous method for upscattering problems\
        - energy parallelization over upscattering means we can use many cores and get good scaling  \
    2) use better eigenvalue algorithm: RQI \
        - extends energy parallelization to all groups; is enabled by block Krylov\
        - converges better for some problems\
        - has convergence issues without preconditioning for many problems\
    3) use a good preconditioner: multilevel in energy\
        - enabled by block Krylov\
        - reduces the number of multigroup iterations\
*** really spell out connection between these. block krylov standalone, accomplishes goal. RQI accomplishes goal, needs precond and block krylov. Precond needs Krylov. ***\
 - Reiteration of why we need fast scalable codes in the nuclear and wider community\
 - The methods employed accomplish this goal; the rest of this report provides the details\
\
\
2. Upscattering and Energy Decomposition\
- The first step on this path is the block Krylov solver since it's needed for the 2nd two methods.\
- chapter preview: \
   why existing parallel decomposition is insufficient, \
   background (solvers, scattering, equations)\
   relevant past work\
   an explanation of the new method, \
   and results from the new method.\
\
 2.1 Denovo and Parallelism\
 - to use machines efficiently we need good scaling, and denovo's scaling behavior is governed by the KBA algorithm\
 - explanation of KBA's parallelization in angle\
 - explanation of KBA's parallelization in space\
 - how to measure the quality of parallelization: theoretical efficiency, weak scaling, strong scaling\
 - Evans did a weak scaling study of X problem and found that the time to solution increased substantially from 4,000 to 40,000 cores: this is not good and is probably from load-balancing latencies. \
 - parallelizing over another dimension will increase decomposition options such that load-balancing could be improved\
 - I did a strong scaling study of X problem with 2 conditions that test how the theoretical efficiency should act\
 - We found that when we use a large number of cores the problem blocks become too small so the communication costs dominate and we can't come close to the theoretical prediction.\
 - With a decomposition that keeps the computational spaces large enough to avoid communication problems, not enough work can be done 
\fs30 at one time.\
 - This means that we need to keep problem blocks large. We can do this by parallelizing in energy.\
\
 2.2 Background\
 - to understand the new method, some background is needed.\
 - this section contains an explanation of scattering, an overview of relevant basic solvers (SI, GS, Krylov), and how we handle scattering in the TE\
\
  2.2.2 Scattering\
  - what is upscattering\
  - why good energy resolution for xsecs w/ upscattering matters for some problems\
  - upscattering and fission couple groups together, leading to inner and outer iteration structure\
\
  2.2.1 Solver Basics\
  - 2 kinds of methods for solving Ax=b: direct and iterative. Why we're doing iterative.\
   2.2.1.1 Richardson/source iteration (SI)\
   - math of how it works\
   - properties \
   - pros and cons\
   2.2.1.2 Gauss Seidel (GS) \
   - math of how it works\
   - properties \
   - pros and cons\
   2.2.1.3 Krylov methods: \
   - math of how it works\
   - properties \
   - pros and cons\
\
  2.2.3 Current Scattering Solution Methods\
  - In denovo we use all three of those methods, set up of equations \
  - here's a matrix that will be used for discussion throughout section\
   2.2.3.1 Downscattering\
   - use forward substitution to solve the series of within-group equations because groups are not coupled\
   - here's what that looks like for each group\
   - here's what it looks like with the example\
   - here's how we solve them for Krylov \
   - the within-group equations are solved iteratively for X reasons\
   2.2.3.2 Upscattering \
   - groups are coupled with upscattering\
   - b/c of coupling we must use some method like GS, and that looks like this\
   - now you can see the inner-outer iteration structure. This cannot be parallelized in energy if GS is used.\
 \
 2.3 Past Work\
 - this section describes how the methods above have been used in the past to handle inner and outer iterations \
 - also demonstrates that no one has used Krylov over multiple groups nor parallelized the equation in energy.\
\
  2.3.1 Inner iterations\
  - traditionally this was done with SI, but SI is really slow\
  - Krylov methods have been developed that are applicable to within-group equations\
  - people are using Krylov for within-group or as part of acceleration so far; 2 exceptions to be discussed later \
  - reasons Krylov has been restricted to within group\
  - we use GMRES for inner iterations in Denovo and that looks like this\
 \
  2.3.2 Outer iterations\
  - GS is used almost universally for outer iterations; not good when problems have high dominance ratios\
  - demo of newness (only examples of almost Krylov over outers):\
    Warsa: multigroup, 3-D TE. preconditioned Krylov for inners, GS or FGMRES(m) for intermediate, and IRAM for veal iters. Sometimes did IRAM initialization with PI. Has a hard time with upscattering, only done in serial. \
use IRAM for TE in serial to do PI, does not handle upscattering well. \
\
  - conclusion: The methods that have been used in the past dictate an inner-outer iteration structure and limit parallelization to space and angle. My method is new. \
\
 2.4 Multigroup Krylov Solver\
 - a new method for upscattering is desired b/c we want to be able to parallelize in energy and use something that converges faster than GS\
\
  2.4.1 Method\
  - explain method\
\
 2.4.2 Results\
  2.4.2.1strong scaling: \
      shows pretty good results \
      some communication issues for really large problems, plan to address this in the future\
  2.4.2.2 gs vs. krylov: shows krylov is faster even in serial\
  2.4.2.3 weak scaling: great results\
\
2.4.3 Implications\
  - faster than gs, parallel in energy\
  - this hasn't been done before b/c of computer limitations and implementation barriers\
  - could have used block Jacobi - but no motivation b/c of computer limitations\
 - conclusion about impact: faster convergence for at least most problems in all cases; allows pretty good scaling to very large machines.\
\
\
3. Eigenvalue Acceleration\
- reminder about why we care about eigenvalues in neutron transport\
- motivation: why we need a better eigenvalue solver\
- chapter preview:\
  background (solver basics)\
  past work\
  an explanation of the new method, \
  results from the new method.\
\
 3.1 Background\
 - connecting ordinary and generalized eigenvalue form\
 - basic notation\
 - this section covers iterative eigenvalue methods 1) used by the nuclear community and 2) needed to understand the new work\
\
   3.1.5 Condition Number and Convergence\
  - define conditioning and condition number\
  - define stability and backwards stability \
  - explain how condition number and backwards stability are related\
  3.1.1 Power Iteration (PI), \
  - math of how it works\
  - algorithm\
  - properties (convergence; dominance ratio)\
  - pros and cons\
  3.1.2 Shifted Inverse Iteration (SII), \
  - math of how it works (extension of PI)\
  - properties (convergence; ill-conditioning)\
  - Wielandt's method\
  - pros and cons\
  3.1.3 Rayleigh Quotient Iteration (RQI),\
  - math of how it works (extension of SII)\
  - algorithm\
  - properties (convergence)\
  - pros and cons\
  3.1.4 Krylov Methods \
  - shifted subspace equivalence\
  - backwards stability\
  - convergence with ill-conditioned systems and the need for preconditioning.\
\
  3.2 Past Work\
 - Here are a bunch of studies that cover\
     Past solution and acceleration methods\
     Results for when Krylov methods are applied ill-conditioned systems\
     What was done in Denovo before this work     \
\
  3.2.1 Eigenvalue Solution Methods\
  - lit review shows SII is better than PI, but that you need a good shift, there are a variety of useful acceleration methods available, and no one has used RQI for TE.\
\
     Allen: 1-group, 1-D TE comparison of PI and SII; SII converges more quickly if a good shift is known (don't describe how to find shift)\
    \
     Itagaki: used SII for 1 and 2 group, 3-D DE using an interesting boundary integral spatial method. Demonstrates theoretically stable convergence if shift is chosen sufficiently close to k. In practice found rapid and stable convergence. \
\
     Hotta: Wielandt showing that convergence depends on good initial guess for flux\
\
     Zinzani: developed version of Wielandt that gets around need for good initial guess. Algorithm is complicated and slow. \
\
  - demonstrates that SII is better than PI, but good shift and eval guess are necessary.\
  - other non-power iteration-based methods have been developed in the last 20 years like\
\
     Suetomi: incomplete factorization preconditioned rayleigh quotient minimization (RQM) of 1-group, 2-D, DE; compare to PI and unpreconditioned RQM. preconditioned RQM is best.\
     Suetomi: extended to few-group, 2-D DE. Have to change to from RQM to conjugate residual (doesn't use RQ). Similar conclusions. \
    Gupta and Modak: extend non-RQ version to the transport equation.\
\
    Vidal: multi-group (1st paper is 2-group then they extend to multi-group - at least the equations), 3-D DE. Select energy groups to only have downscattering. Used unsymmetric and symmetric Rayleigh-Ritz projection (a variation of PI) to find evecs/vals, with the sweeps done by Jacobi-preconditioned CG. Also developed variation acceleration. Compare to chebshev accelerated Arnoldi (2nd paper doesn't use arnoldi).  Arnoldi better for many evils and symmetric RR better for a few. (both papers are the same).\
    Verdu: use IRAM and Rayleigh-Ritz for multigroup (eqns are all 2-group), 3-D DE. Find IRAM is better. Rayleigh-Ritz gets worse when evals are not as separated.\
\
  - these subspace approaches have been applied to DE and some extended to TE.\
  - No one has done RQI for TI. \
\
  3.2.2 Denovo and Power iteration\
 \
  3.2.3 Krylov Methods Concerns\
  - Krylov methods often used in transport, and have shown convergence problems.\
  - Lewis: First was in 1977, likely b/c of large condition number\
  - Rosa: More recent shows that restarted GMRES has trouble in optically thin regions\
  - Oliveira: showed various krylov methods converge slowly for probs of interest\
  - Patton: inspired by convergence problems, they studied preconditioners for GMRES \
  - All of these results indicate that in practice Krylov methods can have serious convergence problems for ill conditioned problems and problems that are optically thin. These are cases of interest, so it is important to be wary of this problem. \
\
 3.3 RQI in Denovo\
 - conclusions from past work: PI is not great, so we def want a better method. We also want the best shift. Leads to selecting RQI. \
 - RQI is enabled by MG Krylov. Added benefit is that it can take greater advantage of energy parallelization. Section preview.\
 \
  3.3.1 Method\
  - explain method\
  - note about fixed-shift option\
  - reflecting boundary considerations\
\
 3.3.2 Results\
 - results showing rqi works at least sometimes\
 - results showing that fixed shift also works, not extensively tested\
 - results showing that rqi really needs preconditioning\
 \
  3.3.3 Implications\
 - better convergence properties than PI; estimates of energy scaling behavior\
 - why it hasn't been done before: \
     computer limitations\
     block Krylov makes this possible b/c of the dense scattering matrix. GS wouldn't be able to do it.\
 - no one has done this before, similar ideas have only been used in DE\
- conclusion about potential impact, especially if preconditioning gets worked out.\
\
\
4. Preconditioning\
- preconditioners are intended to make problems go faster\
- motivation: we need preconditioners to accelerate Krylov methods and to be able to get RQI to converge.\
- chapter preview:\
  background (preconditioner basics, overview of preconditioners, preconditioners in the nuclear community, multilevel methods)\
  past work (preconditioners, multilevel methods)\
  an explanation of the new method, \
  and results from the new method.\
\
 4.1 Background\
 - preconditioning transforms the system you want to solve into an equivalent system that is easier to solve. That looks like this. \
 - a good preconditioner should be cheap and easy to solve while giving faster convergence\
 - preconditioners are bounded by M=I (does nothing) and M=A-1 (just solving)\
  - There are many different kinds of preconditioners. These can be put into two broad categories:\
       - matrix based preconditioners; what they are and when they're useful, (an example ?)\
       - physics based preconditioners; what they are and when they're useful (an example?)\
\
  4.1.1 Preconditioners and the Nuclear Community\
  - a variety are used, some for within-group and some for outer iterations. Here is an overview\
   4.1.1.1 Extrapolation methods \
    - generic description (simple iterative/polynomial)\
    - nuclear specific\
   4.1.1.2 Rebalance \
    - generic description (local approximation)\
    - nuclear specific\
   4.1.1.3 Incomplete Factorizations\
    - generic description \
    - nuclear specific\
   4.1.1.4 Synthetic Acceleration \
    - generic description (low-order approx)\
    - nuclear specific\
\
  4.1.2 Multilevel Methods\
  - multilevel methods can be used as preconditioners or as standalone solvers. can be applied to different problem types. I'm going into them in detail because this is the preconditioner type I used.\
  - multilevel methods work by selectively removing error modes\
  - to explain how that works, use this notation\
  - Fourier modes can be used to express error, and the frequency of the error is expressed by wavenumber\
  - a given error mode can appear smooth or coarse relative to the grid size: a fine grid makes error appear smoother and a coarse grid makes error appear more oscillatory\
  - relaxation (iterative) methods remove oscillatory error very quickly, but do not handle smooth error well. As a result very fine grid spacing can make convergence worse\
  - all of that is used to make multigrid methods: do a few realizations on a fine level to remove oscillatory error, map answer to coarser level where smooth error appears more oscillatory, relax here to remove the now oscillatory error, use answer to correct fine level answer - smooth modes of error should be reduced (see v-cycle algorithm)\
  - a V-cycle is a bunch of v-cycles: go from fine level down multiple levels to a very coarse level, then back up. idea is to remove lots of error modes.\
  - The optimal combination of levels and relaxation count may be problem dependent.\
\
  4.2 Past Work\
  - Here are a bunch of studies that are going to show that 1) preconditioning is needed in general and 2) no one has done multigrid in energy ever before\
  - concrete examples of multilevel methods that have been used and of preconditioning Krylov methods in the nuclear community.\
 \
   4.2.1 Rebalance\
   - has been applied to 3-D TE using MOC with GMRES solver. \
   - This method would need to be changed to apply to Sn.  \
\
   4.2.2 Incomplete Factorizations\
   - Patton: A variety of factorization (matrix) and splitting (physics) methods tried for GMRES with 1-D, multigroup TE using DD. Physics was faster, but DSA was faster than both. \
   - Chen: ILU and MILU to preconditioning CG with SOR for 3-D multigroup TE gave good convergence\
   - Kozlowski: block ILU to precondition multigroup SP3 transport. Too much storage for large problems. \
   - used somewhat widely with mixed success.\
\
   4.2.3 Synthetic Acceleration\
   - wide use of DSA \
   - recent development of TSA - stagnates for GMRES(m). Modified TSA can work for GMRES(m).\
   - DSA in Denovo - useful for diffusive problems with high scattering ratios that are close to being isotropic.\
   - used very widely with a lot of success. Restrictions on DSA can be troublesome, developments of TSA seem promising.\
\
   4.2.4 Multilevel methods\
   - space and angular multigrid have been used as solvers and preconditioners\
    - Sjoden: multigrid in space for 3-D parallel TE\
    - Oliveira: 1-D 1 group, TE used mg in space or angle for krylov; gave better results than ILU\
    - Chang: 2-D spatial mg for isotropic. Had trouble with heterogeneity.\
    - Lee: mg in space and angle at the same time for 2 and 3-D. \
    - not a comprehensive list - but can see space and angle mg have been successfully applied to a wide array of problems types. Never in energy though. \
    4.2.4.1 Two-Grid\
    - 1-level, 1-cycle in angle, applied to TE\
    - requires the diffusion operator to be consistent with transport operator, which is very difficult for some spatial discretizations in multi-D\
    4.2.4.3 Two-Grid in Denovo\
    - Denovo has a transport two grid scheme that extends the method above to use a transport operator so the consistency requirement is removed. \
    - equations\
    - This is cost-effective for problems with many upscattering groups. \
\
   - conclusion: Preconditioners for Krylov is an active area of development and are needed,   \
\
 4.3 Multilevel in Energy \
 - we need preconditioning for x reasons\
 - why we want physics-based\
 - why we chose multilevel in energy\
\
  4.3.1 Method\
  - explain method\
  - include weighted richardson, prolong and restrict, level number selection, weight selection, number of relaxations/level\
  - information about shifted and unshifted operator choice\
  - parallelization\
\
  4.3.2 Results\
  - lay out matrix of options: fixed, pi, rqi; few vs. many groups = energy set investigation; preconditioning parameters. Explain syntax, comparing krylov iters more than timing\
\

\fs28    4.3.2.1 RQI Parameter Scoping\
   - goal 1: verify preconditioner reduces Krylovs with RQI\
   - goal 2: parameter scoping\
   - goal 3: to shift or not to shift\
    1) rqi unit test vac bcs unshifted\
     - correct k and flux were found\
     - preconditioning used fewer Krylov iterations \
     - RQ iterations not affected by preconditioner\
     - need more than just w1r1v1\
     - increasing weight with low r and v requires more iterations\
     - changing weight with large r and v had no effect\
     - using high values for all did not cause the problem to breakdown \
     - r and v have same effect\
    2) rqi unit test vac bcs shifted\
     - k and flux were correct when not preconditioned or sufficiently preconditioned\
     - fewer iterations are needed with the shifted version\
     - shifted version seems less robust\
     - all other previous findings confirmed\
    3) rqi unit test relf bcs unshifted\
     - correct k and flux were found when the problem got the right eigenvector\
     - increasing weight was never useful and can keep problem from converging\
     - preconditioning reduced the number of RQ iterations\
     - did not break down with high r and v values\
    4) rqi unit test relf bcs shifted\
     - this only worked with a lot of preconditioning\
     - increasing weight was always bad\
    all \
     - don't use the shifted operator\
     - correct k and flux were found when the problem converged\
     - preconditioning used fewer Krylov iterations when the problem converged\
     - reflecting decreased RQI, but vacuum didn't\
     - with sufficient preconditioning and vacuum, increasing weight is useful\
     - with reflecting, increasing weight is always bad\
     - more r and v were always good, and they are interchangeable\
   4.3.2.2 Fixed Source Parameter Scoping\
   - goal: preconditioning parameters\
    1) Small Vacuum Test\
     - increasing the weight is beneficial with r1v1 up until some point; there was also a sweet spot.\
     - increasing r and v reduced iteration count until a limit where no further benefit was seen.\
     - lots of preconditioning didn't break anything.\
    2) Small Reflecting Test\
     - weight variation initially beneficial and then detrimental\
     - higher r and v reduce iteration count\
     - increased weight had more influence early on\
     - eventually got down to one iteration\
    all\
     - didn't have trouble with weight at low r and v. small amount of weight is useful here. \
     - confirm r and v trends \
     - These tests were small and easy!\
   4.3.2.3 Fixed Source Solver and Angle Comparisons\
   - goal: compare solvers\
    - preconditioning makes a big difference for this problem\
    - timing was not so favorable\
    - found using S2 in precond was way faster than S8.\
   4.3.2.4 RQI Intermediate Problem\
   - goal: can preconditioner converge the krylov iterations for a problem that did not converge with out it.\
    - RQI basically failed at this for reasons that are unclear. Preconditioning didn't really help.\
    - more r and v were again helpful; r = v in influence. \
    - Tried with RQI and BiCGSTAB; fail.\
    - solved successfully with PI; preconditioning dramatically reduced krylov iterations but took longer. \
   4.3.2.5 2D c5g7 Benchmark\
   - goal 1: can preconditioner converge the krylov iterations for a problem that did not converge with out it.\
   - goal 2: rqi and pi comparison\
   - goal 3: investigate precond parameters in real problems\
    1) PI\
     - all ks were right. \
     - reduced eigenval iter count by 1\
     - small amount of weight was beneficial for small r and v.\
     - high weight prevented convergence\
    2) RQI\
     - all ks were right\
     - with some preconditioning this is held on track enough to get the right k\
     - with a lot of preconditioning everything works. \
     - same weight observations\
     - BiCGSTAB fail\
     - PI had fewer Krylov, less time, but more eval iters on the only comparison case\
   4.3.2.6 3D c5g7\
   - goal: same as 2D, but this is more like an actual problem we want to solve.\
    1) PI\
     - ks all low\
     - precond reduced cry it count substantially, no impact on eigen it\
     - parameter behavior consistent with what was seen before.\
     - with a lot of precond the calculation takes too long\
    2) RQI\
     - all ks low\
     - with small amount of precond, exceeded wall time\
     - with an intermediate amount of preconditioning, this worked great. \
     - RQI beat PI on evals and time, often on Krylov\
    all\
     - RQI can beat PI \
     - RQI needs to be sufficiently preconditioned\
     - small amount of weight is best\
     - intermediate amount of preconditioning is likely best. \
   4.3.2.7 Multisets\
   - goal: how does preconditioner act with multisets\
    1) Fixed Source\
     - all set combinations gave same krylov iteration count\

\fs30      - preconditioner gives super-linear scaling\
    2) infinite medium\
     - all set combinations gave same krylov iteration count\
     - preconditioner gives super-linear scaling\
    3) Full PWR\
     - This is the kind of problem we care about, uses all of the methods together!\
     - RQI faster and fewer iterations than PI with preconditioning for 11 and 22 sets\
\
 - Summary of findings:\
    - 
\fs28 increasing r and v almost always decreases Krylov iteration count; sometimes decreased eigenvalue iteration count\
    - r and v have equal effect, you can put it all in r or all v or split it. Though there is an effect on time. \
    - increasing the weight a small amount is generally beneficial (up to about 1.3 or 1.4), but a large amount is usually detrimental. This is the least consistent parameter, behaving differently in different problems with different degrees of preconditioning. \
    - the weight effect is specific to this relaxation method while r and v are variables that will have to be considered for all relaxation methods.\
    - a moderate amount of preconditioning seems to give the best payoff. Too little doesn't do enough and too much isn't worth the extra time.\
    - improvement from preconditioning has a non-linear relationship, so can't predict ahead of time. \
\
    - the reduced angular expansion may have a lot of pay off. \
    - the shifted operator is definitely a bad idea with reflecting boundaries and is probably a bad idea in general.\
    - always pick GMRES over BiCGSTAB\
\
    - the depth of the V-cycles should probably be set to only one or 2 levels
\fs30 \
\
  4.3.3 Implications\
 - Why mg in energy:\
  1) to enable RQI (which we want), we have to precondition the Krylov solver\
  2) to use big machines we need something that parallelizes in energy easily.\
 - This hasn't been done before because those two drivers didn't exist until recently\
 - Goal of preconditioner is to reduce iteration count, enable rqi, and to be decomposable in energy. The preconditioner does this. 
\fs28 It reduced it count,
\fs30  makes RQI possible, and scales to hundreds of thousands of cores without trouble. \
  \
\
5. Summary and Conclusions\
reinforce connections between methods and point out how they can be used individually. (build a table - but the legs are still useful)\
\

\fs28     - the preconditioner may useful for tough fixed source problems.\
    - seems to work great with PI
\fs30 \

\fs28     - precond is a bit brittle with RQI for problems we could already solve. It seems to work for all of the ones that we couldn't.\
   - reflecting boundaries seem to be much more troublesome for RQI than vacuum. \
   - the preconditioner works great with multisets. \
   - For the kinds of problems we actually care about, it seems like RQI works better than PI. For the easy problems, PI was better. We didn't have a lot of great test problems to really figure this out though. 
\fs30 \
\
\

\fs28  Future work\
  - investigate smaller angle set in preconditioner; if worthwhile extend to reflecting\
  - make rqi work the multisets when there are reflecting boundaries\
  - try changing the depth of the V-cycle and redo a) comparison studies and b) scaling studies\
  - find more high dominance ratio problems to more fully investigate RQI vs. PI\
  - (real work) investigate changing the way convergence in handled in RQI.  \
  - consider other relaxation methods besides weighted Richardson.
\fs30 \
\
\
References\
Appendix A: diffusion method\
Appendix B: Krylov methods\
Appendix C: Reflecting boundary equations\
}